<a href="https://github.com/drshahizan/research-design/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/research-design" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/research-design/network/members"><img src="https://img.shields.io/github/forks/drshahizan/research-design" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/research-design/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/research-design" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/research-design"><img src="https://img.shields.io/github/issues/drshahizan/research-design" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/research-design/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/research-design?color=2b9348"></a>
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan%2MCSD1043&labelColor=%23d9e3f0&countColor=%23697689&style=flat)

# Challenges of Manual Literature Reviews

<p align="center">
<img src="https://www.phdassistance.com/blog/wp-content/uploads/2021/03/PA-Blog-Image_Resize.jpg"  height="600" />
</p>

Imagine you're a data scientist on a critical mission to unearth insights from data. But before you can build your fancy models and algorithms, you need a solid foundation ‚Äì a grasp of what others have discovered in similar territory. This is where the traditional approach of manual literature reviews comes in. However, instead of wrangling data, you're wrestling with research papers ‚Äì a process riddled with challenges that can leave even the most enthusiastic data scientist feeling overwhelmed.

## Information Avalanche
The scientific world is constantly churning out new research. Journals, conferences, and online repositories are overflowing with papers. This exponential growth creates a massive information ocean, making it difficult to find the specific studies most relevant to your data science project. It's like trying to locate a single fish in a vast and ever-expanding sea. Traditional search methods often involve sifting through countless papers, many of which might be irrelevant, leading to frustration and wasted time.

## Time Thief
Even with the most focused search strategy, manual reviews are inherently time-consuming. Each paper requires careful reading, analysis, and potentially note-taking or summarizing. This can quickly become a significant time investment, stealing valuable hours that could be spent on the core tasks of data science ‚Äì building models, analyzing results, and drawing meaningful conclusions. With limited time resources, data scientists might be forced to skim through papers or prioritize readily available sources, potentially missing out on crucial research that could strengthen their project.

## Bias Bug
Humans are wired to have biases, and literature reviews are not immune. Unconscious preferences can influence which papers we choose to focus on or how we interpret them. Confirmation bias, for example, can lead us to favor studies that support our existing ideas, while neglecting those that challenge them. This can create a skewed understanding of the research landscape, potentially leading to flawed conclusions in our own data science projects.  Similarly, availability bias might make us prioritize easily accessible publications over potentially more valuable, but harder-to-find, research.

## Resource Rumble
Conducting thorough manual reviews can be a resource-intensive endeavor.  Academic databases with the most comprehensive collections often come with hefty subscription fees.  This financial barrier can limit access to the most relevant research, especially for individual researchers or smaller teams.  Furthermore, the time commitment associated with manual searching and review represents another resource constraint.  The time spent wrestling with papers detracts from other crucial aspects of data science projects, like data collection, cleaning, and analysis. This creates a resource allocation dilemma, forcing data scientists to make tough choices about where to invest their limited time and budget.

These interconnected challenges highlight the limitations of traditional manual literature reviews in the ever-evolving world of data science.  The sheer volume of information, the risk of bias, and the limitations of time and resources can make it difficult for data scientists to stay ahead of the curve and build upon the work of others.  Fortunately, the field of data science is constantly innovating, and advancements in automated literature review tools offer a glimmer of hope.  These tools act as intelligent assistants, helping data scientists sift through the vast ocean of research and pinpoint the most relevant papers, freeing up valuable time and resources for what they do best ‚Äì uncovering hidden patterns and generating groundbreaking insights from data. 

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/research-design/issues) for any improvements, suggestions or errors in the content.



[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fdrshahizan&labelColor=%23697689&countColor=%23555555&style=plastic)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fdrshahizan)
![](https://hit.yhype.me/github/profile?user_id=81284918)

