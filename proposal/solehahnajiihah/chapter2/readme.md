## INTRODUCTION

There are many techniques developed by researchers over the years regarding sentiment analysis on tourism. Some of them use topic modelling approaches for analysis and interpretation to get a better understanding of the corpus. Several approaches for classification have been introduced using deep learning methods such as long term short term (LTSM), bidirectional  long term short term (bi-LTSM), and transformer-model Bidirectional Encoder Representations (BERT). This chapter will provide the related works done regarding tourism sentiment analysis, topic modelling and deep learning techniques for sentiment classification with details.

## 2.1 Tourism Sentiment Analysis

In the studies of tourism research, it is worth noting that the traditional methods such as questionnaires or surveys are time consuming. For these reasons, only small samples are taken for analysis and thus leads to lack of comprehensiveness. Additionally, due to people's innate emotional cognition and information feedback's passivity, the results are not very representative of the real situation [10]. Other than that, taking into account the human effort which can potentially lead to high risk of bias. On the contrary, social media and review websites act as platforms for active feedback from users sharing their personal experience that is less affected by any kind of influence. Due to these reasons, the incorporation of computer science methods with tourism research is not an uncommon topic. Natural language processing (NLP) techniques have been applied to a variety of tourism-related research projects in several studies [11]. 

In the past studies done on tourism online analysis, researchers divide the sentiment into positive, negative, or neutral as well as multiple types of emotions such as joy, surprise, fear, sadness, etc. [12] based on people’s opinions, reviews and experiences on destinations in a written text. These can provide valuable insights regarding tourist preferences, needs, and experiences for the tourism industry [13]. Irawan et al. determined that emotions are important because they influence ideas and behaviours, propelling actions and influencing decisions in many parts of life. 
Some travellers also use social media as a source to find travel agencies with the best services. In [14], the authors use empirical analysis to investigate the impact of social interface network systems (SNIS) such as Facebook on OTA review generation. Online travel reviews represent the reputation and contentment of travel agencies [3]. Researchers are increasingly interested in applying automated sentiment analysis to tourism data as more users share their travel experiences producing more data for analytics. Recent research in academia and the tourism industry has focused on optimising textual data processing due to advances in computational power and algorithms [15]. 

Some of the research done in the tourism domain is about studying the sentiment of hotel reviews [16, 17, 18], the behaviour of tourists, travel services, tourism destinations and tourism sentiment analysis for the tourism recommendation system. Cao et al. explore the emotional features of Chinese visitors visiting heritage sites in Melaka and discover factors impacting their positive and negative feelings by using sentiment analysis techniques [9]. The results indicate positive assessments are attributed to the destination's material culture, cultural ambiance, and topography. On the other hand, negative feelings result from a lack of cultural exposure, which makes Chinese visitors feel bored. This study focuses on analysing the affective nature of the tourists for enhancing the services and implementing sustainable tourism development. The use of deep learning in sentiment analysis helps improve the strategic marketing of Chinese tourists and support the long-term viability of heritage tourism destinations.

Alrashidi et al. compile the First Dataset for Tweets Saudi Tourism (FDTST) in both Arabic and English languages, then analyse review sentiment using machine learnings to offer insightful information regarding Saudi Arabia's tourism sector [19]. The authors discovered that machine learning models such as Support Vector Machine (SVM) and Naïve Bayes (NB) are effective at classifying sentiments, with SVM having better performance. Insights gained from the study can contribute to the improvement of hospitality and tourism services, urging industry stakeholders to monitor social media, aligning with Saudi Arabia’s Vision 2023. 

A study to analyse a tourist destination specifically Granada in Spain using aspect-based sentiment analysis (ABSA) was done by Viñan-Ludeña and De Campos [20]. The study's goal is to use sentiment analysis techniques to identify relevant entities (locations) and aspects to improve the growth of the tourism industry based on TripAdvisor user reviews. The authors use several approaches for sentiment classification including deep learning models. The data collect tourist reviews from Twitter and Instagram sites and use the BERT model to classify the sentiment (positive, negative, or neutral) for Spanish text while Tweeteval is used for English data. The research's conclusions offer crucial information for improving destination perception, establishing reputation management, and creating effective marketing strategies. The study also provides more comprehension of how social media influences destination perceptions and customer experience. 

Mehra presented a study on predicting the behavioural intentions of foreign tourists exposed to culture shock or other surprises in three Asian countries [21]. The author uses ABSA and emotion analysis (EA) on user generated contents (UGCs) in exploring how emotions and sentiments derived from these comments may affect post travel behaviour.  The study discovers that the allure of a destination affects the feelings of travellers, with neutral feelings like surprise causing either retreat or unfavourable reactions, particularly when brought on by culture shock. Negative remarks are sparked by negative feelings from bad experiences, and sad feeling is a key factor between visitors' experiences and their post-visit behavioural intentions. Sad feelings are mostly caused by things like food and bathrooms in China, women's empowerment and alcohol in the UAE, traffic, hygiene, time, and poverty in India. The study comes to the conclusion that emotions have a complex and non-linear influence on behavioural intentions, and that passive behaviour may be more harmful than displeasure.

## 2.2 Topic-Based Sentiment Analysis
	
Tourism sentiment analysis is done to get better understanding and discover opinions about specific topics or entities. Traditional studies of sentiment analysis detect the general sentiment towards the entire sentence or document by making predictions at the sentence or document level [22]. Sentiment analysis at the document level assesses the sentiment present in complete documents such as reviews and categorises them as objective or subjective. Sentence-level sentiment analysis evaluates emotions within sentences and offers insights into opinions and expressions [23]. Aspect level analysis provides a more fine-grained level of opinions and sentiment analysis at aspect-level. 

Topic-based sentiment analysis aims to locate particular opinion targets or topic terms in text and evaluate the sentiment that is expressed about them. This method enables a thorough comprehension of user perceptions regarding specific topics [24]. Topic modelling is the process of locating underlying semantic structures in massive document collections by using statistical techniques namely  Latent Semantic Analysis (LSA), Non-Negative Matrix Factorization (NMF) [25] and Latent Dirichlet Allocation (LDA) [11,26,27,28]. It is an unsupervised Machine Learning (ML) technique used in Natural Language Processing (NLP) to find topics in a document or corpus. A topic modelling algorithm shown in Figure which accepts an input a set of text documents and generates a list of topics, or major themes represented by word clusters that may have overlapping meanings. A document's topic distribution, which shows the relative importance of each topic, defines each topic based on the weighted frequency of terms inside it [16]. 

Latent Semantic Analysis (LSA), also referred to as Latent Semantic Indexing (LSI), is based on the distributional hypothesis, which states that words with comparable meanings emerge in similar contexts. LSA derives semantic relationships directly from the text corpus by computing similarities between texts using vector representations. It begins with a term-document matrix and applies the bag-of-words model for identifying latent topics using singular value decomposition (SVD) which reduces the dimensionality. Term Frequency-Inverse Document Frequency (TF-IDF) is used for weighting terms, enhancing the importance of less common but informative words. LSA is a faster algorithm and simple for implementation because of simple matrix decomposition. However, it provides less accuracy than Latent Dirichlet Allocation (LDA) [29].

Non-Negative Matrix Factorization (NMF) does not require labelled training data. It decomposes high dimension vectors (term-document matrix) into a non-negative lower-dimensional form and was developed to remove negative components of data models. NMF presents data in a more interpretable and accurate form of the data. Two matrices, W (m×k), a document-topic matrix and H (n×k), a topic-term matrix are created from an input matrix V (k×n) in this method. V is the document-term matrix input, each row in H is the word embedding, and each column in W indicates the weight of each word in each sentence. Several limitations of NMF is it provides more general topics rather than nuanced insights and is less efficient with large scale text data [30,31,32]. In [29], the authors did empirical evaluation between LDA and LSA on three different datasets, with the former producing more coherent topics than the latter.

LDA, a widely used method in topic modelling analysis [16,24,33,34,35], divides words in documents into several topics. The LDA method does not take into account the order of documents in collection and the order of words in a text. It generates topics by combining the probabilities of underlying topics. The advantage of the LDA model is that it is effective in discovering latent topics in large datasets, easy to implement, comprehend and use, however it needs to be pre-defined by the number of topics. Topic coherence measures are done by Ali et al. in their study to find the optimum number of topics [24]. The semantic similarity between the most popular terms within a given topic is measured by topic coherence, which shows how closely related the words are to one another. A higher coherence score indicates a greater likelihood of the terms representing a meaningful and coherent topic. Figure shows the example of underlying terms of each topic using the LDA method. Another limitation of LDA is its ability to produce topics that are not coherence and might lose the context of a text as it does not consider the relationships between words. It struggles with capturing complex data relationships and performs badly with shorter documents.

On the contrary, the advancement in pre-trained language models (PLMs) using transformer-models like Bidirectional Encoder Representations from Transformers (BERT) has contributed to topic modelling studies. In [36], the author uses BERT embeddings with the concept of class-based variation of TF-IDF (cTF-IDF) to produce coherent and interpretable topics that are identified by automatically generated labels. It creates document embeddings using pre-trained language, Sentence-BERT [37], capturing the semantic relationships between documents and clustering them accurately rather than just frequency of words. Though, the author specifies any other embedding technique can be used as long as they are fine-tuned on semantic similarity. The document embeddings created are high-dimensional, and Uniform Manifold Approximation and Projection (UMAP) [38] is used for dimensionality reduction while preserving the essential relationships and structure of the original high-dimensional data. Then, clustering techniques such as Hierarchical density based clustering (HDBSCAN) [39] is applied to create topic clusters. After clustering, BERTopic builds topic representations using a class-based variant of TF-IDF. This strategy emphasises the most important terms related with each topic, giving coherent and understandable topic descriptions. Figure shows the algorithm of BERTopic by Groontendorst. 

Several studies have been done utilising BERTopic to identify and extract the topics in text and compared it with other topic modelling techniques [25,28,40,41,42]. Kastrati et al. (2023) analyse and investigate the public engagement on increases in energy prices on Twitter, combining BERT for sentiment analysis and BERTopic and LDA on identifying the topics for better understanding on social media. The authors find that BERTopic gives more coherent and interpretable topics compared to LDA which highlight the advantage of BERTopic in capturing the semantic relationship between words using embedded transformers [43]. BERTopic offers several advantages over traditional topic modelling methods such as being able to understand the structure of a text by providing both the topics and the most representative words and phrases [ ]. 

## 2.3 Sentiment Classification

Over the years, there have been many studies proposing many approaches to sentiment analysis that can be categorised into three types; lexicon-based, machine learning including deep learning and hybrid. Lexicon methods use sentiment-expressing words to predict the orientation of subjective content in text documents [44,45]. Machine learning provides semi-supervised or supervised models for sentiment analysis with the latter being a commonly used method. Supervised method determines the polarity sentiment of a document based on labelled datasets. Its main advantage is the ability to create efficient models in a specific domain but lacks the efficiency when applied across domains [46]. The previous study involves machine learning methods such as Support Vector Machine (SVM) and Naive-Bayes (NB). These methods necessitate the manual selection of features or the development of methods of selecting features. Thus, the quality of sentiment analysis results is determined by the manual selection criteria [47].
	
Deep learning approach has received popularity among researchers and in production, ranging from computer vision (CV), natural language processing (NLP) and audio processing. It has shown promising results in several sentiment analysis studies [26,33,35]. Deep learning's success in natural language processing (NLP) is largely attributable to the word embedding technique (Word2Vec, GloVe) used for language modelling and feature extraction. This method transforms the vocabulary into dense vectors of real numbers that efficiently capture semantic and syntactic similarities between words and other linguistic patterns [48]. The most widely used deep learning architectures are long short-term memory (LTSM), convolutional neural networks (CNN) and gated recurrent neural networks (GRU). Recently, an innovative approach has evolved that uses large language models to produce contextualised embeddings, allowing for greater comprehension of varied meanings depending on the context. Bidirectional Encoder Representations from Transformers (BERT) is designed to pre-train deep bidirectional representations by conditioning on both left and right contexts in all layers. This enables BERT to capture more nuanced meanings of words depending on their surrounding context. 

Several studies have been done comparing the performance of deep learning models and language models such as LTSM, GRU, Bi-LTSM, RNN, BERT, Roberta and Electra [35,49,50]. In [51], the authors evaluated the performance of RNN, LSTM and GRU for sentiment analysis on reviews and proposed a fusion model integrating RNN variant with the output of CNN. BiLSTM and BiGRU have better mean accuracy compared to LSTM and GRU. In natural language processing, bidirectional models are  preferred for understanding the context of the sentence, providing better classification results by processing information from both past and future states. Mishra et al. conducted a study on the impact of COVID-19 on the tourism industry using the LSTM-RNN model [35]. LSTM networks are designed to handle sequential data, such as text or time series, by capturing word dependencies and associations, which is critical for sentiment analysis. Their distinct architecture incorporates memory cells that preserve information over long sequences, addressing the vanishing gradient problem encountered in regular RNNs and allowing the model to recall significant information while processing new inputs. 
